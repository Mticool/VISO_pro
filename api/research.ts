import type { VercelRequest, VercelResponse } from '@vercel/node';

export default async function handler(req: VercelRequest, res: VercelResponse) {
  // CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const { topic } = req.body;

    if (!topic) {
      return res.status(400).json({ error: 'Topic is required' });
    }

    console.log(`üîç Perplexity Research: "${topic}"`);

    const perplexityKey = process.env.PERPLEXITY_API_KEY;

    if (!perplexityKey) {
      console.log('‚ö†Ô∏è No Perplexity API key, skipping research');
      return res.status(200).json({ context: '', skipped: true });
    }

    const response = await fetch('https://api.perplexity.ai/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${perplexityKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama-3.1-sonar-large-128k-online',
        messages: [
          {
            role: 'system',
            content: '–¢—ã ‚Äî –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ù–∞–π–¥–∏ —Å–∞–º—É—é —Å–≤–µ–∂—É—é –∏ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ. –í–µ—Ä–Ω–∏ –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ: –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, —Ç—Ä–µ–Ω–¥—ã, –Ω–æ–≤–æ—Å—Ç–∏. –§–æ—Ä–º–∞—Ç: bullet points. –ú–∞–∫—Å–∏–º—É–º 300 —Å–ª–æ–≤.'
          },
          {
            role: 'user',
            content: `–ù–∞–π–¥–∏ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ: "${topic}"`
          }
        ],
        max_tokens: 1024,
        temperature: 0.2,
      }),
    });

    if (!response.ok) {
      throw new Error(`Perplexity API error: ${response.status}`);
    }

    const data = await response.json();
    const context = data.choices?.[0]?.message?.content || '';

    console.log(`‚úÖ Research complete (${context.length} chars)`);

    return res.status(200).json({ context });

  } catch (error) {
    console.error('‚ùå Research error:', error);
    return res.status(200).json({ context: '', error: true });
  }
}

